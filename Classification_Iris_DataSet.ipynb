{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification-Iris-DataSet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyAwqG/3OxYwmfhYkQPuFn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrightonOtieno/Classification-IrisDataSet-Tensorflow/blob/master/Classification_Iris_DataSet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ig76VFbqWQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5vdLM69tJ6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import  absolute_import,division,print_function,unicode_literals"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2SJLt9htVoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMebfTyHtdjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CSV_COLUMN_NAMES = ['SepalLength','SepalWidth','PetalLength','PetalWidth','Species']\n",
        "SPECIES = ['Setosa','Versicolor','Virginica']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7urfzxvuS9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = tf.keras.utils.get_file('iris_training.csv','https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8STAT4mEwdWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_path = tf.keras.utils.get_file('iris_testing.csv','https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTrw5b6vw8yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(train_path,names=CSV_COLUMN_NAMES,header=0)\n",
        "test = pd.read_csv(test_path,names=CSV_COLUMN_NAMES,header=0)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcAPNg3gxXh9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4a44bbae-c8b1-42f6-c9e7-2cb55d10978d"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
              "0          5.9         3.0          4.2         1.5        1\n",
              "1          6.9         3.1          5.4         2.1        2\n",
              "2          5.1         3.3          1.7         0.5        0\n",
              "3          6.0         3.4          4.5         1.6        1\n",
              "4          5.5         2.5          4.0         1.3        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "494sEfWhxaBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "aa907260-db74-4623-8442-a75d7cf9dbaf"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
              "0          6.4         2.8          5.6         2.2        2\n",
              "1          5.0         2.3          3.3         1.0        1\n",
              "2          4.9         2.5          4.5         1.7        2\n",
              "3          4.9         3.1          1.5         0.1        0\n",
              "4          5.7         3.8          1.7         0.3        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjKIyw3Axch7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = train.pop('Species')\n",
        "test_y = test.pop('Species')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjvn_jixyCoq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4a9cf306-3915-49e7-d52c-fe8d68f3d15a"
      },
      "source": [
        "train_y.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2\n",
              "1    1\n",
              "2    2\n",
              "3    0\n",
              "4    0\n",
              "Name: Species, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKzlCfRLyGcz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "90af5a4d-7799-49bd-9372-575127186004"
      },
      "source": [
        "test_y.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    2\n",
              "2    0\n",
              "3    1\n",
              "4    1\n",
              "Name: Species, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o336QJ-5yKAm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b98ce1d9-c9a3-4ab1-fc35-c2a78cf4b8fa"
      },
      "source": [
        "print(train_y.shape)\n",
        "print(train.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120,)\n",
            "(120, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii8dOUplySz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d9d38f65-69af-4d1b-ce6a-1ab0033d59a6"
      },
      "source": [
        "print(test_y.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30,)\n",
            "(30, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEudil3M6G0M",
        "colab_type": "text"
      },
      "source": [
        "## Input Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f34sTUc-yc_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn(features,labels,training=True,batch_size=256):\n",
        "  #convert the input into Dataset\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(features),labels))\n",
        "  # shuffle and repeat while Training\n",
        "  if training:\n",
        "    dataset = dataset.shuffle(1000).repeat()\n",
        "\n",
        "  return dataset.batch(batch_size)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzhkJamW2c54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l8icBEc6M9l",
        "colab_type": "text"
      },
      "source": [
        "## Feature Columns\n",
        "* loop through the columns in  the train data frame\n",
        "* confirm that columns are numeric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTeDIhJS6QlZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8551ab8e-85b4-47ad-8b81-eb3c373ddfb9"
      },
      "source": [
        "my_feature_columns= []\n",
        "for key in train.keys():\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "print(my_feature_columns)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLIUPc5b7mL5",
        "colab_type": "text"
      },
      "source": [
        "# Building Classification Model\n",
        "*  we could use\n",
        "### LinearClassifier Model (except that it assumes linear relationship between  features and response/label)\n",
        "\n",
        "### DNNClassifier works great with non-linear too "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaSN7jIP7eQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "b5405854-c3b1-4641-e4d1-4565a834b2a3"
      },
      "source": [
        "classifier = tf.estimator.DNNClassifier(feature_columns=my_feature_columns,\n",
        "                                        hidden_units=[30,10],\n",
        "                                        n_classes=3)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_4yfrdka\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_4yfrdka', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WVZt63S9t-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5e2080e-0fdd-4e26-c099-f538544e5310"
      },
      "source": [
        "classifier.train(\n",
        "    input_fn = lambda:input_fn(train,train_y,training=True),\n",
        "    steps = 5000\n",
        ")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp_4yfrdka/model.ckpt-5000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp_4yfrdka/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
            "INFO:tensorflow:loss = 0.5285808, step = 5000\n",
            "INFO:tensorflow:global_step/sec: 390.116\n",
            "INFO:tensorflow:loss = 0.522825, step = 5100 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.221\n",
            "INFO:tensorflow:loss = 0.50848925, step = 5200 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 412.996\n",
            "INFO:tensorflow:loss = 0.51077855, step = 5300 (0.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.806\n",
            "INFO:tensorflow:loss = 0.50330603, step = 5400 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.876\n",
            "INFO:tensorflow:loss = 0.4986525, step = 5500 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 565.413\n",
            "INFO:tensorflow:loss = 0.49530256, step = 5600 (0.176 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 5670 vs previous value: 5670. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 468.852\n",
            "INFO:tensorflow:loss = 0.49648234, step = 5700 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.802\n",
            "INFO:tensorflow:loss = 0.46689996, step = 5800 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 461.256\n",
            "INFO:tensorflow:loss = 0.4865231, step = 5900 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 454.63\n",
            "INFO:tensorflow:loss = 0.47633788, step = 6000 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 489.728\n",
            "INFO:tensorflow:loss = 0.47848356, step = 6100 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.099\n",
            "INFO:tensorflow:loss = 0.46924293, step = 6200 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 463.061\n",
            "INFO:tensorflow:loss = 0.47760156, step = 6300 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.099\n",
            "INFO:tensorflow:loss = 0.46521348, step = 6400 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.358\n",
            "INFO:tensorflow:loss = 0.4684383, step = 6500 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.961\n",
            "INFO:tensorflow:loss = 0.47280723, step = 6600 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.59\n",
            "INFO:tensorflow:loss = 0.4455303, step = 6700 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.164\n",
            "INFO:tensorflow:loss = 0.44928414, step = 6800 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.081\n",
            "INFO:tensorflow:loss = 0.44574946, step = 6900 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.417\n",
            "INFO:tensorflow:loss = 0.4393502, step = 7000 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.642\n",
            "INFO:tensorflow:loss = 0.44420308, step = 7100 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.344\n",
            "INFO:tensorflow:loss = 0.45270836, step = 7200 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 540.159\n",
            "INFO:tensorflow:loss = 0.42919445, step = 7300 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.965\n",
            "INFO:tensorflow:loss = 0.43400782, step = 7400 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.463\n",
            "INFO:tensorflow:loss = 0.4187001, step = 7500 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 465.017\n",
            "INFO:tensorflow:loss = 0.43795645, step = 7600 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.091\n",
            "INFO:tensorflow:loss = 0.42067736, step = 7700 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 480.122\n",
            "INFO:tensorflow:loss = 0.43528816, step = 7800 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.298\n",
            "INFO:tensorflow:loss = 0.42367697, step = 7900 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.78\n",
            "INFO:tensorflow:loss = 0.415617, step = 8000 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.58\n",
            "INFO:tensorflow:loss = 0.40730098, step = 8100 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.977\n",
            "INFO:tensorflow:loss = 0.4081096, step = 8200 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.416\n",
            "INFO:tensorflow:loss = 0.40743276, step = 8300 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 434.602\n",
            "INFO:tensorflow:loss = 0.40257853, step = 8400 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.409\n",
            "INFO:tensorflow:loss = 0.39623868, step = 8500 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.652\n",
            "INFO:tensorflow:loss = 0.39472544, step = 8600 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.54\n",
            "INFO:tensorflow:loss = 0.39596927, step = 8700 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.457\n",
            "INFO:tensorflow:loss = 0.39776856, step = 8800 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 453.678\n",
            "INFO:tensorflow:loss = 0.39085767, step = 8900 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.929\n",
            "INFO:tensorflow:loss = 0.37838706, step = 9000 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.335\n",
            "INFO:tensorflow:loss = 0.38920182, step = 9100 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 580.703\n",
            "INFO:tensorflow:loss = 0.3796233, step = 9200 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.397\n",
            "INFO:tensorflow:loss = 0.3755718, step = 9300 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.991\n",
            "INFO:tensorflow:loss = 0.38142097, step = 9400 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.695\n",
            "INFO:tensorflow:loss = 0.37526613, step = 9500 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.141\n",
            "INFO:tensorflow:loss = 0.38048702, step = 9600 (0.177 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 9634 vs previous value: 9634. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 536.828\n",
            "INFO:tensorflow:loss = 0.36900908, step = 9700 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.626\n",
            "INFO:tensorflow:loss = 0.37168264, step = 9800 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.668\n",
            "INFO:tensorflow:loss = 0.36773783, step = 9900 (0.185 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10000...\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmp_4yfrdka/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10000...\n",
            "INFO:tensorflow:Loss for final step: 0.3521418.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7fbc15c85908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4L_qjanAq7P",
        "colab_type": "text"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH_v69wMAt3s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "13dd9f5f-d1c6-4f51-c557-46f557ef7066"
      },
      "source": [
        "eval_result =  classifier.evaluate(input_fn=lambda:input_fn(test,test_y,training=False))\n",
        "print('\\nTest set accuracy:{accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-09-06T06:10:01Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp_4yfrdka/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.22754s\n",
            "INFO:tensorflow:Finished evaluation at 2020-09-06-06:10:01\n",
            "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.93333334, average_loss = 0.43400526, global_step = 10000, loss = 0.43400526\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/tmp_4yfrdka/model.ckpt-10000\n",
            "\n",
            "Test set accuracy:0.933\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2V7ASs_VpWm",
        "colab_type": "text"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyooAF-kBiRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn(features,batch_size=256):\n",
        "   # Takes in parameters such as (sepal lenght and ,width petal length and Width)\n",
        "   #convert the inputs into Dataset without Labels\n",
        "   return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "# Input Parameters\n",
        "features = ['SepalLength','SepalWidth','PetalLength','PetalWidth']\n",
        "predict = {}\n",
        "# Promt user to enter data\n",
        "print('please type NUMERIC VALUES as Prompted')\n",
        "for feature  in features:\n",
        "  valid = True\n",
        "  while valid:\n",
        "    val = input(feature+ \":\")\n",
        "    if not  val.isdigit():\n",
        "      valid = false # will break out of the loop\n",
        "\n",
        "    else: # implying that the input value is a digit\n",
        "      predict[feature] = [float(val)] \n",
        "      # conver value to float and pass it into the dictionary as a list(tensorflow style) \n",
        "\n",
        "# Do the predictions\n",
        "predictions = classifier.predict(\n",
        "    input_fn = lambda:input_fn(predict)\n",
        ")\n",
        "\n",
        "# Print the CLASS and PROBABILITY \n",
        "for prediction in predictions:\n",
        "  class_id = prediction['class_ids'][0]\n",
        "  probability = prediction['probabilities'][class_id]\n",
        "  print('Prediction is \"{}\"({:.1f}%)'.format(SPECIES[class_id],100*probability))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGMOqcVOdxM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}